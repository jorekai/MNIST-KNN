{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST KNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2bVk+2RvMj4OrfASWSOI7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"6KOFWgNlQSUP","executionInfo":{"status":"ok","timestamp":1601300441520,"user_tz":-120,"elapsed":1000,"user":{"displayName":"N J","photoUrl":"","userId":"00389130294464925219"}},"outputId":"137634a2-68f2-477e-a6f8-dd2fe05b6736","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Keras datasets offers mnist as dataset\n","from keras.datasets import mnist\n","import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import linear_model\n","from sklearn import preprocessing\n","# load dataset via keras api\n","(trainX, trainy), (testX, testy) = mnist.load_data()\n","# Shapes are not yet flattened, outputs the shapes\n","# Shapes must be 2-D, 3-D fitting not supported\n","trainX = trainX.reshape(60000, 28*28)\n","testX = testX.reshape(10000, 28*28)\n","print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n","print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train: X=(60000, 784), y=(60000,)\n","Test: X=(10000, 784), y=(10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q_jmkVs5dINP","executionInfo":{"status":"ok","timestamp":1601300441979,"user_tz":-120,"elapsed":1454,"user":{"displayName":"N J","photoUrl":"","userId":"00389130294464925219"}},"outputId":"be8c8458-fe47-4612-8a9f-66835d076b4f","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# make models with sklearns classifier, vary model to see different classification\n","knn_3 = KNeighborsClassifier(n_neighbors=3)\n","knn_6 = KNeighborsClassifier(n_neighbors=6)\n","knn_12 = KNeighborsClassifier(n_neighbors=12)\n","# fit the training values to target values small set\n","knn_3.fit(trainX[1:10], trainy[1:10])\n","# fit the training values to target values complete set\n","# knn_3.fit(trainX, trainy)\n","# knn_6.fit(trainX, trainy)\n","# knn_12.fit(trainX, trainy)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n","                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n","                     weights='uniform')"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"2P6orKv2ddwc","executionInfo":{"status":"ok","timestamp":1601300441979,"user_tz":-120,"elapsed":1448,"user":{"displayName":"N J","photoUrl":"","userId":"00389130294464925219"}},"outputId":"46b7ace3-8570-4665-d14d-be355f4de212","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# see the scored results of the knn on a subset, the whole set takes super long\n","# comment out to wait an eternity, exchange for classifier Model\n","# knn_3.score(testX, testy)\n","print('KNN score: {}'.format(knn_3.score(testX[1:250], testy[1:250])))\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["KNN score: 0.2570281124497992\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K6HGsDHRzXMq","executionInfo":{"status":"ok","timestamp":1601300441980,"user_tz":-120,"elapsed":1444,"user":{"displayName":"N J","photoUrl":"","userId":"00389130294464925219"}},"outputId":"cac66738-7f84-4a23-d54c-565754b3027c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Predictions Length which label fits to the testing data\n","# the True Values show which labels have been predicted correctly\n","prediction = knn_3.predict(testX[0:100])==testy[0:100]\n","print(np.sum(prediction))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["27\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nK_4JGDgzY_f"},"source":["Task 13(MNIST knn) is over here. Below the effect of feature normalization is shown. Also LogisticRegression is used on the CIFAR set\n"]},{"cell_type":"code","metadata":{"id":"J61gXXcOgteI","executionInfo":{"status":"ok","timestamp":1601300494699,"user_tz":-120,"elapsed":54150,"user":{"displayName":"N J","photoUrl":"","userId":"00389130294464925219"}},"outputId":"f789ca7a-cb6f-49b1-a8c1-2df41b2b9039","colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# comparison to logistic regression\n","logistic = linear_model.LogisticRegression(max_iter=150)\n","print('LogisticRegression score: {}'.format(logistic.fit(trainX, trainy).score(testX[1:250], testy[1:250])))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["LogisticRegression score: 0.9437751004016064\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Rb2A-e1DjdvJ","executionInfo":{"status":"ok","timestamp":1601300500554,"user_tz":-120,"elapsed":59992,"user":{"displayName":"N J","photoUrl":"","userId":"00389130294464925219"}},"outputId":"95fba78d-89f4-41e2-cb67-dc13ea7c257b","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# sklearn is asking us to scale down our data, well do this with Normalization\n","#(trainX, trainy), (testX, testy) = mnist.load_data()\n","trainX_scaled = preprocessing.normalize(trainX, norm='l2')\n","testX_scaled = preprocessing.normalize(testX, norm='l2')\n","trainy_scaled = preprocessing.normalize(trainy.reshape(-1, 1), norm='l2')\n","testy_scaled = preprocessing.normalize(testy.reshape(-1, 1), norm='l2')\n","# score is now higher and computation time goes down\n","print('LogisticRegression score: {}'.format(logistic.fit(trainX_scaled, trainy_scaled).score(testX_scaled, testy_scaled)))\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["LogisticRegression score: 0.9917\n"],"name":"stdout"}]}]}